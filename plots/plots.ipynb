{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..', 'utils'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import format_time as ft\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import griddata\n",
    "from adjustText import adjust_text\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "SAMPLES = 50000\n",
    "\n",
    "FIGURES_PATH = '../figures/'\n",
    "isExist = os.path.exists(FIGURES_PATH)\n",
    "if not isExist:\n",
    "    os.makedirs(FIGURES_PATH)\n",
    "\n",
    "RESULTS_PATH = '../results_all/'\n",
    "# SERVER_PATH = RESULTS_PATH + 'server_3090/results_100epochs_128batch/'\n",
    "SERVER_PATH = RESULTS_PATH + 'server_a2000/results_100epochs_128batch/'\n",
    "# SERVER_PATH = RESULTS_PATH + 'server_3080/results_100epochs_128batch/'\n",
    "path_elements = SERVER_PATH.split('/')\n",
    "server_element = [element for element in path_elements if 'server' in element]\n",
    "SERVER_NAME = server_element[0]\n",
    "\n",
    "\n",
    "df_nostats_train = pd.read_csv(SERVER_PATH + r'mlresults_nostats_train.csv')\n",
    "df_nostats_train['duration(s)'] = df_nostats_train['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_nostats_train['step(ms)'] = df_nostats_train['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_stats_train = pd.read_csv(SERVER_PATH + r'mlresults_stats_train.csv')\n",
    "df_stats_train['duration(s)'] = df_stats_train['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_stats_train['step(ms)'] = df_stats_train['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_eco2ai_train = pd.read_csv(SERVER_PATH + r'mlresults_eco2ai_nostats_train.csv')\n",
    "df_eco2ai_train['duration(s)'] = df_eco2ai_train['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_eco2ai_train['step(ms)'] = df_eco2ai_train['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_codecarbon_train = pd.read_csv(SERVER_PATH + r'mlresults_codecarbon_nostats_train.csv')\n",
    "df_codecarbon_train['duration(s)'] = df_codecarbon_train['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_codecarbon_train['step(ms)'] = df_codecarbon_train['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_carbontracker_train = pd.read_csv(SERVER_PATH + r'mlresults_carbontracker_nostats_train.csv')\n",
    "df_carbontracker_train['duration(s)'] = df_carbontracker_train['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_carbontracker_train['step(ms)'] = df_carbontracker_train['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_nostats_test = pd.read_csv(SERVER_PATH + r'mlresults_nostats_test.csv')\n",
    "df_nostats_test['duration(s)'] = df_nostats_test['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_nostats_test['step(ms)'] = df_nostats_test['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_stats_test = pd.read_csv(SERVER_PATH + r'mlresults_stats_test.csv')\n",
    "df_stats_test['duration(s)'] = df_stats_test['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_stats_test['step(ms)'] = df_stats_test['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_eco2ai_test = pd.read_csv(SERVER_PATH + r'mlresults_eco2ai_nostats_test.csv')\n",
    "df_eco2ai_test['duration(s)'] = df_eco2ai_test['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_eco2ai_test['step(ms)'] = df_eco2ai_test['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_codecarbon_test = pd.read_csv(SERVER_PATH + r'mlresults_codecarbon_nostats_test.csv')\n",
    "df_codecarbon_test['duration(s)'] = df_codecarbon_test['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_codecarbon_test['step(ms)'] = df_codecarbon_test['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_carbontracker_test = pd.read_csv(SERVER_PATH + r'mlresults_carbontracker_nostats_test.csv')\n",
    "df_carbontracker_test['duration(s)'] = df_carbontracker_test['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "df_carbontracker_test['step(ms)'] = df_carbontracker_test['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "\n",
    "df_codecarbon = pd.read_csv(SERVER_PATH + r'emissions.csv')\n",
    "df_codecarbon_results_train = pd.DataFrame(df_codecarbon.values[::2],index=df_codecarbon.index[::2],columns=df_codecarbon.columns).reset_index(drop=True)\n",
    "df_codecarbon_results_test = pd.DataFrame(df_codecarbon.values[1::2],index=df_codecarbon.index[1::2],columns=df_codecarbon.columns).reset_index(drop=True)\n",
    "\n",
    "df_eco2ai = pd.read_csv(SERVER_PATH + r'resultsEco2AI.csv')\n",
    "df_eco2ai_results_train = pd.DataFrame(df_eco2ai.values[::2],index=df_eco2ai.index[::2],columns=df_eco2ai.columns).reset_index(drop=True)\n",
    "df_eco2ai_results_test = pd.DataFrame(df_eco2ai.values[1::2],index=df_eco2ai.index[1::2],columns=df_eco2ai.columns).reset_index(drop=True)\n",
    "\n",
    "with open(SERVER_PATH + 'stats_train.json') as f:\n",
    "    stats_train = json.load(f)\n",
    "stats_train = stats_train['exp_0']\n",
    "\n",
    "with open(SERVER_PATH + 'stats_test.json') as f:\n",
    "    stats_test = json.load(f)\n",
    "stats_test = stats_test['exp_0']\n",
    "\n",
    "with open(SERVER_PATH + 'model_size.json') as f:\n",
    "    model_size = json.load(f)\n",
    "\n",
    "def add_label(x, y, val, ax, distance=0, other=None):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    texts = []\n",
    "    for i, point in a.iterrows():\n",
    "        if other is None:\n",
    "            texts.append(ax.text(point['x']+distance, point['y'], str(point['val'])))\n",
    "        else:\n",
    "            texts.append(ax.text(point['x']+distance, point['y'], str(point['val']) + str(other)))\n",
    "    adjust_text(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"project_name\", y=\"accuracy\", data=df_stats_test, estimator=np.max, errorbar=None)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Max Accuracy')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "\n",
    "# Adding text labels above the bars\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width() / 2., p.get_height(),\n",
    "            '{:.2f}%'.format(p.get_height()), # You can format it as you like\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/max_model_accuracy_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"project_name\", y=\"duration(s)\", data=df_stats_train, estimator=np.mean, errorbar=('sd',3))\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Average Training Duration per Epoch (std of +/-3)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Duration (ms)\")\n",
    "\n",
    "# Adding text labels above the bars\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width() / 2., p.get_height(),\n",
    "            '{:.0f}ms'.format(p.get_height()), # You can format it as you like\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/model_training_per_epoch_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"project_name\", y=\"duration(s)\", data=df_stats_test, estimator=np.mean, errorbar=('sd',3))\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Average Testing Duration per 50k samples (std of +/-3)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Duration (ms)\")\n",
    "\n",
    "# Adding text labels above the bars\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width() / 2., p.get_height()+100,\n",
    "            '{:.0f}ms'.format(p.get_height()), # You can format it as you like\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/model_testing_per_50ksamples_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duration_df = pd.merge(df_nostats_train, df_stats_train, on=['project_name', 'epoch'], suffixes=('_nostats', '_frost'))\n",
    "merged_duration_df.rename(columns={\"duration(s)_nostats\": \"NoTool\"}, inplace=True)\n",
    "merged_duration_df.rename(columns={\"duration(s)_frost\": \"FROST\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_eco2ai_train, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"duration(s)\": \"Eco2AI\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_codecarbon_train, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"duration(s)\": \"CodeCarbon\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_carbontracker_train, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"duration(s)\": \"CarbonTracker\"}, inplace=True)\n",
    "merged_duration_df = merged_duration_df[['project_name', 'NoTool', 'FROST', 'Eco2AI', 'CodeCarbon', 'CarbonTracker']]\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\", font_scale=2.5)\n",
    "\n",
    "sns.catplot(x=\"project_name\", y=\"value\", hue=\"variable\", kind=\"bar\", errorbar=lambda x: (x.min(), x.max()), data=pd.melt(merged_duration_df, id_vars=['project_name']), height=16, aspect=2/1, legend_out=False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Runtime (training)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Milliseconds (ms)\")\n",
    "plt.legend(loc='upper right', title='Experiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/runtime_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "merged_duration_df = pd.merge(df_nostats_train, df_stats_train, on=['project_name', 'epoch'], suffixes=('_nostats', '_frost'))\n",
    "merged_duration_df.rename(columns={\"step(ms)_nostats\": \"NoTool\"}, inplace=True)\n",
    "merged_duration_df.rename(columns={\"step(ms)_frost\": \"FROST\"}, inplace=True)\n",
    "\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_eco2ai_train, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"step(ms)\": \"Eco2AI\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_codecarbon_train, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"step(ms)\": \"CodeCarbon\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_carbontracker_train, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"step(ms)\": \"CarbonTracker\"}, inplace=True)\n",
    "merged_duration_df = merged_duration_df[['project_name', 'NoTool', 'FROST', 'Eco2AI', 'CodeCarbon', 'CarbonTracker']]\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\", font_scale=2.5)\n",
    "\n",
    "sns.catplot(x=\"project_name\", y=\"value\", hue=\"variable\", kind=\"bar\", errorbar=lambda x: (x.min(), x.max()), data=pd.melt(merged_duration_df, id_vars=['project_name']), height=16, aspect=2/1, legend_out=False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Runtime per batch (training)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Milliseconds (ms)\")\n",
    "plt.legend(loc='upper right', title='Experiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/runtime_per_batch_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duration_df = pd.merge(df_nostats_test, df_stats_test, on=['project_name', 'epoch'], suffixes=('_nostats', '_frost'))\n",
    "merged_duration_df.rename(columns={\"duration(s)_nostats\": \"NoTool\"}, inplace=True)\n",
    "merged_duration_df.rename(columns={\"duration(s)_frost\": \"FROST\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_eco2ai_test, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"duration(s)\": \"Eco2AI\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_codecarbon_test, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"duration(s)\": \"CodeCarbon\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_carbontracker_test, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"duration(s)\": \"CarbonTracker\"}, inplace=True)\n",
    "merged_duration_df = merged_duration_df[['project_name', 'NoTool', 'FROST', 'Eco2AI', 'CodeCarbon', 'CarbonTracker']]\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\", font_scale=2.5)\n",
    "\n",
    "sns.catplot(x=\"project_name\", y=\"value\", hue=\"variable\", kind=\"bar\", errorbar=lambda x: (x.min(), x.max()), data=pd.melt(merged_duration_df, id_vars=['project_name']), height=16, aspect=2/1, legend_out=False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Runtime (testing)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Milliseconds (ms)\")\n",
    "plt.legend(loc='upper right', title='Experiment')\n",
    "plt.savefig(FIGURES_PATH + '/runtime_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "merged_duration_df = pd.merge(df_nostats_test, df_stats_test, on=['project_name', 'epoch'], suffixes=('_nostats', '_frost'))\n",
    "merged_duration_df.rename(columns={\"step(ms)_nostats\": \"NoTool\"}, inplace=True)\n",
    "merged_duration_df.rename(columns={\"step(ms)_frost\": \"FROST\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_eco2ai_test, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"step(ms)\": \"Eco2AI\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_codecarbon_test, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"step(ms)\": \"CodeCarbon\"}, inplace=True)\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_carbontracker_test, on=['project_name', 'epoch'])\n",
    "merged_duration_df.rename(columns={\"step(ms)\": \"CarbonTracker\"}, inplace=True)\n",
    "merged_duration_df = merged_duration_df[['project_name', 'NoTool', 'FROST', 'Eco2AI', 'CodeCarbon', 'CarbonTracker']]\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\", font_scale=2.5)\n",
    "\n",
    "sns.catplot(x=\"project_name\", y=\"value\", hue=\"variable\", kind=\"bar\", errorbar=lambda x: (x.min(), x.max()), data=pd.melt(merged_duration_df, id_vars=['project_name']), height=16, aspect=2/1, legend_out=False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Runtime per batch (testing)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Milliseconds (ms)\")\n",
    "plt.legend(loc='upper right', title='Experiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/runtime_per_batch_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train_tmp = stats_train.copy()\n",
    "\n",
    "models = df_stats_train.project_name.unique()\n",
    "\n",
    "for model in models:\n",
    "    tmp_dict = stats_train_tmp[model]\n",
    "    if model in model_size.keys():\n",
    "        model_size_tmp = model_size[model]\n",
    "        for epoch in tmp_dict.keys():\n",
    "            filtered = filter(lambda num: num >= 0, tmp_dict[epoch]['cpu_delta_power_w'])\n",
    "            tmp_dict[epoch]['cpu_delta_power_w'] = list(filtered)\n",
    "\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'start_time'] = tmp_dict[epoch]['start_time']\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'stop_time'] = tmp_dict[epoch]['stop_time']\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'cpu_energy_uj'] = np.mean(tmp_dict[epoch]['cpu_energy_uj'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'cpu_delta_power_w'] = np.mean(tmp_dict[epoch]['cpu_delta_power_w'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'cpu_percent'] = np.mean(tmp_dict[epoch]['cpu_percent'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'cpu_memory_percent'] = np.mean(tmp_dict[epoch]['cpu_memory_percent'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'cpu_temperature_c'] = np.mean(tmp_dict[epoch]['cpu_temperature_c'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'gpu_power_w'] = np.mean(tmp_dict[epoch]['gpu_power_w'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'gpu_temperature_c'] = np.mean(tmp_dict[epoch]['gpu_temperature_c'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'gpu_memory_free_b'] = np.mean(tmp_dict[epoch]['gpu_memory_free_b'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'gpu_memory_used_b'] = np.mean(tmp_dict[epoch]['gpu_memory_used_b'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'gpu_percent'] = np.mean(tmp_dict[epoch]['gpu_percent'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'ram_power_w'] = np.mean(tmp_dict[epoch]['ram_power_w'])\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'size_mb'] = model_size_tmp['size_mb']\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'parameters'] = model_size_tmp['parameters']\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'buffer'] = model_size_tmp['buffer']\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'macs'] = model_size_tmp['macs']\n",
    "            df_stats_train.loc[(df_stats_train['project_name'] == model) & (df_stats_train['epoch'] == int(epoch)), 'trainable_params'] = model_size_tmp['trainable_params']\n",
    "\n",
    "stats_test_tmp = stats_test.copy()\n",
    "\n",
    "models = df_stats_test.project_name.unique()\n",
    "\n",
    "for model in models:\n",
    "    tmp_dict = stats_test_tmp[model]\n",
    "    if model in model_size.keys():\n",
    "        model_size_tmp = model_size[model]\n",
    "        for epoch in tmp_dict.keys():\n",
    "            filtered = filter(lambda num: num >= 0, tmp_dict[epoch]['cpu_delta_power_w'])\n",
    "            tmp_dict[epoch]['cpu_delta_power_w'] = list(filtered)\n",
    "            \n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'start_time'] = tmp_dict[epoch]['start_time']\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'stop_time'] = tmp_dict[epoch]['stop_time']\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'cpu_energy_uj'] = np.mean(tmp_dict[epoch]['cpu_energy_uj'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'cpu_delta_power_w'] = np.mean(tmp_dict[epoch]['cpu_delta_power_w'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'cpu_percent'] = np.mean(tmp_dict[epoch]['cpu_percent'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'cpu_memory_percent'] = np.mean(tmp_dict[epoch]['cpu_memory_percent'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'cpu_temperature_c'] = np.mean(tmp_dict[epoch]['cpu_temperature_c'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'gpu_power_w'] = np.mean(tmp_dict[epoch]['gpu_power_w'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'gpu_temperature_c'] = np.mean(tmp_dict[epoch]['gpu_temperature_c'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'gpu_memory_free_b'] = np.mean(tmp_dict[epoch]['gpu_memory_free_b'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'gpu_memory_used_b'] = np.mean(tmp_dict[epoch]['gpu_memory_used_b'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'gpu_percent'] = np.mean(tmp_dict[epoch]['gpu_percent'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'ram_power_w'] = np.mean(tmp_dict[epoch]['ram_power_w'])\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'size_mb'] = model_size_tmp['size_mb']\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'parameters'] = model_size_tmp['parameters']\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'buffer'] = model_size_tmp['buffer']\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'macs'] = model_size_tmp['macs']\n",
    "            df_stats_test.loc[(df_stats_test['project_name'] == model) & (df_stats_test['epoch'] == int(epoch)), 'trainable_params'] = model_size_tmp['trainable_params']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"project_name\", y=\"cpu_delta_power_w\", data=df_stats_train, estimator= np.max, errorbar=None)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Average CPU power consumption (training)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Average CPU power (W)\")\n",
    "\n",
    "# Adding text labels above the bars\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width() / 2., p.get_height(),\n",
    "            '{:.2f}W'.format(p.get_height()), # You can format it as you like\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/avg_cpu_power_consumption_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"project_name\", y=\"cpu_delta_power_w\", data=df_stats_test, estimator= np.max, errorbar=None)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Average CPU power consumption (testing)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Average CPU power (W)\")\n",
    "\n",
    "# Adding text labels above the bars\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width() / 2., p.get_height(),\n",
    "            '{:.2f}W'.format(p.get_height()), # You can format it as you like\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/avg_cpu_power_consumption_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"project_name\", y=\"gpu_power_w\", data=df_stats_train, estimator=lambda x: np.mean(x)/1000)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Average GPU power consumption (training)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Average GPU power (W)\")\n",
    "\n",
    "# Adding text labels above the bars\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width() / 2., p.get_height(),\n",
    "            '{:.2f}W'.format(p.get_height()), # You can format it as you like\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/avg_gpu_power_consumption_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"project_name\", y=\"gpu_power_w\", data=df_stats_test, estimator=lambda x: np.mean(x)/1000)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Average GPU power consumption (testing)')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Average GPU power (W)\")\n",
    "\n",
    "# Adding text labels above the bars\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width() / 2., p.get_height(),\n",
    "            '{:.2f}W'.format(p.get_height()), # You can format it as you like\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/avg_gpu_power_consumption_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['gpu_power_w'] = round(df_stats_train_tmp['gpu_power_w']/1000, 2)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)},style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"gpu_power_w\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Average GPU power consumption as a function of the utilisation (training)')\n",
    "plt.xlabel(\"Average GPU power (W)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_power_vs_utilisation_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['gpu_power_w'] = round(df_stats_train_tmp['gpu_power_w']/1000, 2)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)},style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"gpu_power_w\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Average GPU power consumption as a function of the utilisation (training)')\n",
    "plt.xlabel(\"Average GPU power (W)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "plt.xlim(60, None)\n",
    "plt.ylim(80, None)\n",
    "# add_label(df_stats_train_tmp.gpu_power_w, df_stats_train_tmp.gpu_percent, df_stats_train_tmp.project_name, plt.gca(), 0.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_power_vs_utilisation_training_zoom_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['cpu_delta_power_w'] = round(df_stats_train_tmp['cpu_delta_power_w'],2)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"cpu_delta_power_w\", y=\"cpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Average CPU power consumption as a function of the utilisation (training)')\n",
    "plt.xlabel(\"Average CPU power (W)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/cpu_power_vs_utilisation_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_test_tmp = df_stats_test.groupby('project_name').mean().reset_index()\n",
    "df_stats_test_tmp['gpu_power_w'] = round(df_stats_test_tmp['gpu_power_w']/1000, 2)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"gpu_power_w\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name', s=150)\n",
    "plt.title('Average GPU power consumption as a function of the utilisation (testing)')\n",
    "plt.xlabel(\"Average GPU power (W)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_power_vs_utilisation_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_test_tmp = df_stats_test.groupby('project_name').mean().reset_index()\n",
    "df_stats_test_tmp['cpu_delta_power_w'] = round(df_stats_test_tmp['cpu_delta_power_w'],2)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"cpu_delta_power_w\", y=\"cpu_percent\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name', s=150)\n",
    "plt.title('Average CPU power consumption as a function of the utilisation (testing)')\n",
    "plt.xlabel(\"Average CPU power (W)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/cpu_power_vs_utilisation_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['total'] = (df_stats_train_tmp['cpu_delta_power_w'] + (df_stats_train_tmp['gpu_power_w']/1000) + df_stats_train_tmp['ram_power_w']) * (df_stats_train_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"total\", y=\"accuracy\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Total power consumption as a function of the accuracy (training)')\n",
    "plt.xlabel(\"Total power consumption (Wh)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_train_tmp.total, df_stats_train_tmp.accuracy, df_stats_train_tmp.project_name, plt.gca(), 2)\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/total_power_vs_accuracy_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['gpu_power_w'] = round(df_stats_train_tmp['gpu_power_w']/1000, 2)\n",
    "df_stats_train_tmp['gpu_memory_used_b'] = round(df_stats_train_tmp['gpu_memory_used_b']/pow(10, 9), 2)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"gpu_power_w\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', size='gpu_memory_used_b', sizes=(50, 500))\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "plt.legend(h[1:15],l[1:15], loc='lower right', title='Experiment')\n",
    "plt.title('Average GPU power consumption - dot size represents the GPU RAM usage (training)')\n",
    "plt.xlabel(\"Average GPU power (W)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.ylim(0, 100)\n",
    "for index, row in df_stats_train_tmp.iterrows():\n",
    "    ax.annotate(f\"{row['gpu_memory_used_b']}GB\", (row['gpu_power_w'] + 0.2, row['gpu_percent']))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_power_vs_utilisation_vs_gpu_ram_use_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"gpu_power_w\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', size='gpu_memory_used_b', sizes=(50, 500))\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "plt.legend(h[1:15],l[1:15], loc='lower right', title='Experiment')\n",
    "plt.title('Average GPU power consumption - dot size represents the GPU RAM usage (training)')\n",
    "plt.xlabel(\"Average GPU power (W)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.xlim(66, None)\n",
    "plt.ylim(88, 100)\n",
    "\n",
    "add_label(df_stats_train_tmp.gpu_power_w, df_stats_train_tmp.gpu_percent, df_stats_train_tmp.gpu_memory_used_b, plt.gca(), 0.01, 'GB') \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_power_vs_utilisation_vs_gpu_ram_use_training_zoom_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['size_mb'] = round(df_stats_train_tmp['size_mb'], 1)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"size_mb\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation by model size (training)')\n",
    "plt.xlabel(\"Model size (MB)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_train_tmp.size_mb, df_stats_train_tmp.gpu_percent, df_stats_train_tmp.project_name, plt.gca(), 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_vs_model_size_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_test_tmp = df_stats_test.groupby('project_name').mean().reset_index()\n",
    "df_stats_test_tmp['size_mb'] = round(df_stats_test_tmp['size_mb'], 1)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"size_mb\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation by model size (testing)')\n",
    "plt.xlabel(\"Model size (MB)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_test_tmp.size_mb, df_stats_test_tmp.gpu_percent, df_stats_test_tmp.project_name, plt.gca(), 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_vs_model_size_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['parameters'] = df_stats_train_tmp['parameters']/pow(10, 6)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"parameters\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation by no. of parameters (training)')\n",
    "plt.xlabel(\"Parameters (no. in millions)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_train_tmp.parameters, df_stats_train_tmp.gpu_percent, df_stats_train_tmp.project_name, plt.gca(), 0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_vs_no_parameters_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_test_tmp = df_stats_test.groupby('project_name').mean().reset_index()\n",
    "df_stats_test_tmp['parameters'] = df_stats_test_tmp['parameters']/pow(10, 6)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"parameters\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation by no. of parameters (testing)')\n",
    "plt.xlabel(\"Parameters (no. in millions)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_test_tmp.parameters, df_stats_test_tmp.gpu_percent, df_stats_test_tmp.project_name, plt.gca(), 0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_vs_no_parameters_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['trainable_params'] = df_stats_train_tmp['trainable_params']/pow(10, 6)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"trainable_params\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation by trainable parameters (training)')\n",
    "plt.xlabel(\"Parameters (no. in millions)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_train_tmp.trainable_params, df_stats_train_tmp.gpu_percent, df_stats_train_tmp.project_name, plt.gca(), 0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_vs_no_trainable_parameters_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_test_tmp = df_stats_test.groupby('project_name').mean().reset_index()\n",
    "df_stats_test_tmp['trainable_params'] = df_stats_test_tmp['trainable_params']/pow(10, 6)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"trainable_params\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation by trainable parameters (training)')\n",
    "plt.xlabel(\"Parameters (no. in millions)\")\n",
    "plt.ylabel(\"Utilisation (%)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_test_tmp.trainable_params, df_stats_test_tmp.gpu_percent, df_stats_test_tmp.project_name, plt.gca(), 0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_vs_no_trainable_parameters_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['macs'] = df_stats_train_tmp['macs']/pow(10, 6)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"macs\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation by MAC operations (training)')\n",
    "plt.xlabel(\"Parameters (no. in millions)\")\n",
    "plt.ylabel(\"Multiply-Accumulate Operations (no. in millions)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_train_tmp.macs, df_stats_train_tmp.gpu_percent, df_stats_train_tmp.project_name, plt.gca(), 0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_vs_macs_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_test_tmp = df_stats_test.groupby('project_name').mean().reset_index()\n",
    "df_stats_test_tmp['macs'] = df_stats_test_tmp['macs']/pow(10, 6)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"macs\", y=\"gpu_percent\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation by MAC operations (training)')\n",
    "plt.xlabel(\"Parameters (no. in millions)\")\n",
    "plt.ylabel(\"Multiply-Accumulate Operations (no. in millions)\")\n",
    "plt.legend(loc='lower right', title='Experiment')\n",
    "add_label(df_stats_test_tmp.macs, df_stats_test_tmp.gpu_percent, df_stats_test_tmp.project_name, plt.gca(), 0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_vs_macs_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['macs'] = df_stats_train_tmp['macs']/pow(10, 6)\n",
    "df_stats_train_tmp['size_mb'] = round(df_stats_train_tmp['size_mb'], 1)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"size_mb\", y=\"macs\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Model size as a function of the MAC operations')\n",
    "plt.xlabel(\"Model Size (MB)\")\n",
    "plt.ylabel(\"Multiply-Accumulate Operations (no. in millions)\")\n",
    "plt.legend(loc='upper right', title='Experiment')\n",
    "add_label(df_stats_train_tmp.size_mb, df_stats_train_tmp.macs, df_stats_train_tmp.project_name, plt.gca(), 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/model_size_vs_macs_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "merged_df = merged_df[['project_name', 'gpu_percent']]\n",
    "merged_df = pd.merge(merged_df, df_stats_test.groupby('project_name').mean().reset_index(), on=['project_name'])\n",
    "merged_df = merged_df[['project_name', 'gpu_percent_y', 'gpu_percent_x']]\n",
    "merged_df.rename(columns={'gpu_percent_x': 'gpu_percent_train', 'gpu_percent_y': 'gpu_percent_test'}, inplace=True)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"gpu_percent_train\", y=\"gpu_percent_test\", hue=\"project_name\", data=merged_df, style='project_name', s=150)\n",
    "plt.title('GPU Utilisation for training and testing')\n",
    "plt.xlabel(\"Utilisation - training (%)\")\n",
    "plt.ylabel(\"Utilisation - testing (%)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/gpu_utilisation_training_vs_testing' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "merged_df['gpu_power_w_train'] = round(merged_df['gpu_power_w']/1000, 2)\n",
    "merged_df['gpu_memory_used_b_train'] = round(merged_df['gpu_memory_used_b']/pow(10, 9), 2)\n",
    "merged_df = merged_df[['project_name', 'gpu_power_w_train', 'gpu_memory_used_b_train']]\n",
    "merged_df = pd.merge(merged_df, df_stats_test.groupby('project_name').mean().reset_index(), on=['project_name'])\n",
    "merged_df['gpu_power_w_testing'] = round(merged_df['gpu_power_w']/1000, 2)\n",
    "merged_df['gpu_memory_used_b_testing'] = round(merged_df['gpu_memory_used_b']/pow(10, 9), 2)\n",
    "merged_df = merged_df[['project_name', 'gpu_power_w_train', 'gpu_memory_used_b_train', 'gpu_power_w_testing', 'gpu_memory_used_b_testing']]\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"gpu_power_w_train\", y=\"gpu_power_w_testing\", hue=\"project_name\", data=merged_df, style='project_name', s=150)\n",
    "plt.title('GPU power consumption for training and testing')\n",
    "plt.xlabel(\"GPU Power - training (Wh)\")\n",
    "plt.ylabel(\"GPU Power - testing (Wh)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/gpu_power_training_vs_testing' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "merged_df['total_training'] = (merged_df['cpu_delta_power_w'] + (merged_df['gpu_power_w']/1000) + merged_df['ram_power_w']) * (merged_df['duration(s)']/1000*EPOCHS / 3600)\n",
    "merged_df = merged_df[['project_name', 'total_training']]\n",
    "merged_df = pd.merge(merged_df, df_stats_test.groupby('project_name').mean().reset_index(), on=['project_name'])\n",
    "merged_df['total_testing'] = (merged_df['cpu_delta_power_w'] + (merged_df['gpu_power_w']/1000) + merged_df['ram_power_w']) * (merged_df['duration(s)']/1000*EPOCHS / 3600)\n",
    "merged_df = merged_df[['project_name', 'total_training', 'total_testing']]\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.scatterplot(x=\"total_training\", y=\"total_testing\", hue=\"project_name\", data=merged_df, style='project_name', s=150)\n",
    "plt.title('Total power consumption for training and testing')\n",
    "plt.xlabel(\"Total Power - training (Wh)\")\n",
    "plt.ylabel(\"Total Power - testing (Wh)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "add_label(merged_df.total_training, merged_df.total_testing, merged_df.project_name, plt.gca(), 1)\n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/total_power_training_vs_testing' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['total'] = (df_stats_train_tmp['cpu_delta_power_w'] + (df_stats_train_tmp['gpu_power_w']/1000) + df_stats_train_tmp['ram_power_w']) * (df_stats_train_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"total\", y=\"size_mb\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Total power consumption as a function of the model size (training)')\n",
    "plt.xlabel(\"Total power consumption (Wh)\")\n",
    "plt.ylabel(\"Model size (MB)\")\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, 80)\n",
    "plt.legend(loc='upper right', title='Experiment')\n",
    "add_label(df_stats_train_tmp.total, df_stats_train_tmp.size_mb, df_stats_train_tmp.project_name, plt.gca(), 2)\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/total_power_vs_model_size_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_test_tmp = df_stats_test.groupby('project_name').mean().reset_index()\n",
    "df_stats_test_tmp['total'] = (df_stats_test_tmp['cpu_delta_power_w'] + (df_stats_test_tmp['gpu_power_w']/1000) + df_stats_test_tmp['ram_power_w']) * (df_stats_test_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"total\", y=\"size_mb\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name', s=150)\n",
    "plt.title('Total power consumption as a function of the model size (testing)')\n",
    "plt.xlabel(\"Total power consumption (Wh)\")\n",
    "plt.ylabel(\"Model size (MB)\")\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, 80)\n",
    "plt.legend(loc='upper right', title='Experiment')\n",
    "add_label(df_stats_test_tmp.total, df_stats_test_tmp.size_mb, df_stats_test_tmp.project_name, plt.gca(), 2)\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/total_power_vs_model_size_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['macs'] = df_stats_train_tmp['macs'] / pow(10, 6)\n",
    "df_stats_train_tmp['parameters'] = df_stats_train_tmp['parameters'] / pow(10, 6)\n",
    "df_stats_train_tmp['trainable_params'] = df_stats_train_tmp['trainable_params'] / pow(10, 6)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"macs\", y=\"parameters\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Multiply–Accumulate Operations as a function of the no. of parameters')\n",
    "plt.xlabel(\"MACs (no. in millions)\")\n",
    "plt.ylabel(\"Parameters (no. in millions)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "add_label(df_stats_train_tmp.macs, df_stats_train_tmp.parameters, df_stats_train_tmp.project_name, plt.gca(), 2) \n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/macs_vs_no_parameters_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"macs\", y=\"trainable_params\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Multiply–Accumulate Operations as a function of the no. of trainable parameters')\n",
    "plt.xlabel(\"MACs (no. in millions)\")\n",
    "plt.ylabel(\"Trainable Parameters (no. in millions)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "add_label(df_stats_train_tmp.macs, df_stats_train_tmp.trainable_params, df_stats_train_tmp.project_name, plt.gca(), 2) \n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/macs_vs_no_trainable_parameters_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['total'] = (df_stats_train_tmp['cpu_delta_power_w'] + (df_stats_train_tmp['gpu_power_w']/1000) + df_stats_train_tmp['ram_power_w']) * (df_stats_train_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "df_stats_train_tmp['macs'] = df_stats_train_tmp['macs'] / pow(10, 6)\n",
    "df_stats_train_tmp['parameters'] = df_stats_train_tmp['parameters'] / pow(10, 6)\n",
    "df_stats_train_tmp['trainable_params'] = df_stats_train_tmp['trainable_params'] / pow(10, 6)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"total\", y=\"macs\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Total power consumption as a function of the Multiply–Accumulate Operations (training)')\n",
    "plt.xlabel(\"Total power consumption (Wh)\")\n",
    "plt.ylabel(\"MACs (no. in millions)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "add_label(df_stats_train_tmp.total, df_stats_train_tmp.macs, df_stats_train_tmp.project_name, plt.gca(), 2) \n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/total_power_vs_macs_training_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_test_tmp = df_stats_test.groupby('project_name').mean().reset_index()\n",
    "df_stats_test_tmp['total'] = (df_stats_test_tmp['cpu_delta_power_w'] + (df_stats_test_tmp['gpu_power_w']/1000) + df_stats_test_tmp['ram_power_w']) * (df_stats_test_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"total\", y=\"macs\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name', s=150)\n",
    "plt.title('Total power consumption as a function of the Multiply–Accumulate Operations (testing)')\n",
    "plt.xlabel(\"Total power consumption (Wh)\")\n",
    "plt.ylabel(\"MACs (no. in millions)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "add_label(df_stats_test_tmp.total, df_stats_test_tmp.macs, df_stats_test_tmp.project_name, plt.gca(), 2) \n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/total_power_vs_macs_testing_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['total'] = (df_stats_train_tmp['cpu_delta_power_w'] + (df_stats_train_tmp['gpu_power_w']/1000) + df_stats_train_tmp['ram_power_w']) * (df_stats_train_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "df_stats_train_tmp['macs'] = df_stats_train_tmp['macs'] / pow(10, 6)\n",
    "df_stats_train_tmp['parameters'] = df_stats_train_tmp['parameters'] / pow(10, 6)\n",
    "df_stats_train_tmp['trainable_params'] = df_stats_train_tmp['trainable_params'] / pow(10, 6)\n",
    "\n",
    "df_stats_train_tmp['macs_param'] = df_stats_train_tmp['macs'] / df_stats_train_tmp['trainable_params']\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.scatterplot(x=\"total\", y=\"macs_param\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name', s=150)\n",
    "plt.title('Total power consumption as a function of the MACs per parameter')\n",
    "plt.xlabel(\"Total power consumption (Wh)\")\n",
    "plt.ylabel(\"MACs per parameter (no. in millions)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "add_label(df_stats_train_tmp.total, df_stats_train_tmp.macs_param, df_stats_train_tmp.project_name, plt.gca(), 2) \n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/total_power_vs_macs_per_parameter_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_train_tmp = df_stats_train\n",
    "df_stats_train_tmp['total'] = (df_stats_train_tmp['cpu_delta_power_w'] + (df_stats_train_tmp['gpu_power_w']/1000) + df_stats_train_tmp['ram_power_w']) * (df_stats_train_tmp['duration(s)']/1000 / 3600)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.lineplot(x=\"epoch\", y=\"total\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name')\n",
    "plt.title('Average power consumption as a function of the number of epochs (training)')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Total power consumption (Wh)\")\n",
    "plt.legend(loc='lower left', title='Experiment')\n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/avg_energy_consumed_per_epoch_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_train_tmp = df_stats_train\n",
    "df_stats_train_tmp['line_power'] = (df_stats_train_tmp['cpu_delta_power_w'] + (df_stats_train_tmp['gpu_power_w']/1000) + df_stats_train_tmp['ram_power_w']) * (df_stats_train_tmp['duration(s)']/1000)\n",
    "df_stats_train_tmp['total'] = df_stats_train_tmp.groupby('project_name')['line_power'].cumsum() / 3600\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.lineplot(x=\"epoch\", y=\"total\", hue=\"project_name\", data=df_stats_train_tmp, style='project_name')\n",
    "plt.title('Average power consumption as a function of the number of epochs (training)')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Total power consumption (Wh)\")\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/total_energy_consumed_per_epoch_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_test_tmp = df_stats_test\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "line_plot = sns.lineplot(x=\"epoch\", y=\"accuracy\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name')\n",
    "plt.title('Epochs and accuracy')\n",
    "plt.xlabel(\"Epochs (no.)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend(loc='lower left', title='Experiment')\n",
    "\n",
    "unique_project_names = merged_df['project_name'].unique()\n",
    "iterator = 0\n",
    "for line in line_plot.lines:\n",
    "    line_name = line.get_label()\n",
    "    if \"child\" in line_name:\n",
    "        x = line.get_xdata()\n",
    "        y = line.get_ydata()\n",
    "\n",
    "        if x.size > 0 and y.size > 0:\n",
    "            t = line_plot.text(x[-1], y[-1], unique_project_names[iterator], horizontalalignment='left', size='small', color=line.get_color())\n",
    "            t.set_bbox(dict(facecolor='white', edgecolor='black'))\n",
    "        \n",
    "        iterator += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/epoch_vs_accuracy_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "df_stats_test_tmp = df_stats_test\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,6.27)}, style=\"whitegrid\")\n",
    "line_plot = sns.lineplot(x=\"epoch\", y=\"accuracy\", hue=\"project_name\", data=df_stats_test_tmp, style='project_name')\n",
    "plt.title('Epochs and accuracy (zoomed in)')\n",
    "plt.xlabel(\"Epochs (no.)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend(loc='lower left', title='Experiment')\n",
    "plt.xlim(80, None)\n",
    "plt.ylim(65, None)\n",
    "\n",
    "unique_project_names = merged_df['project_name'].unique()\n",
    "iterator = 0\n",
    "for line in line_plot.lines:\n",
    "    line_name = line.get_label()\n",
    "    if \"child\" in line_name:\n",
    "        x = line.get_xdata()\n",
    "        y = line.get_ydata()\n",
    "\n",
    "        if x.size > 0 and y.size > 0:\n",
    "            t = line_plot.text(x[-1], y[-1], unique_project_names[iterator], horizontalalignment='left', size='small', color=line.get_color())\n",
    "            t.set_bbox(dict(facecolor='white', edgecolor='black'))\n",
    "        \n",
    "        iterator += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH + '/epoch_vs_accuracy_zoom_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_stats_train\n",
    "merged_df = merged_df.sort_values(['project_name', 'epoch'])\n",
    "merged_df['line_power'] = (merged_df['cpu_delta_power_w'] + (merged_df['gpu_power_w']/1000) + merged_df['ram_power_w']) * (merged_df['duration(s)']/1000)\n",
    "merged_df['total'] = merged_df.groupby('project_name')['line_power'].cumsum() / 3600\n",
    "merged_df = merged_df[['project_name', 'epoch', 'total']]\n",
    "merged_df = pd.merge(merged_df, df_stats_test, on=['project_name', 'epoch'])\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "line_plot = sns.lineplot(x=\"accuracy\", y=\"total\", hue=\"project_name\", data=merged_df, style='project_name')\n",
    "plt.legend(loc='upper left', title='Experiment')\n",
    "plt.title('Average power consumption as a function of the accuracy')\n",
    "plt.ylabel(\"Total power consumption (Wh)\")\n",
    "plt.xlabel(\"Accuracy (%)\")\n",
    "plt.xlim(70, None)\n",
    "\n",
    "unique_project_names = merged_df['project_name'].unique()\n",
    "iterator = 0\n",
    "for line in line_plot.lines:\n",
    "    line_name = line.get_label()\n",
    "    if \"child\" in line_name:\n",
    "        x = line.get_xdata()\n",
    "        y = line.get_ydata()\n",
    "\n",
    "        if x.size > 0 and y.size > 0:\n",
    "            t = line_plot.text(x[-1], y[-1], unique_project_names[iterator], horizontalalignment='left', size='large', color=line.get_color())\n",
    "            t.set_bbox(dict(facecolor='white', edgecolor='black'))\n",
    "        \n",
    "        iterator += 1\n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/avg_energy_consumed_vs_accuracy_per_epoch' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_stats_train\n",
    "# merged_df = merged_df.sort_values(['project_name', 'epoch'])\n",
    "merged_df['line_power'] = (merged_df['cpu_delta_power_w'] + (merged_df['gpu_power_w']/1000) + merged_df['ram_power_w']) * (merged_df['duration(s)']/1000)\n",
    "merged_df['total'] = merged_df.groupby('project_name')['line_power'].cumsum() / 3600\n",
    "\n",
    "# Convert 'project_name' to ordinal\n",
    "unique_projects = merged_df['project_name'].unique()\n",
    "project_dict = {project: i for i, project in enumerate(unique_projects)}\n",
    "project_ids = merged_df['project_name'].map(project_dict)\n",
    "\n",
    "# Define grid\n",
    "xi = np.linspace(project_ids.min(), project_ids.max(), 100)\n",
    "yi = np.linspace(merged_df['total'].min(), merged_df['total'].max(), 100)\n",
    "xi, yi = np.meshgrid(xi, yi)\n",
    "\n",
    "# Interpolate\n",
    "zi = griddata((project_ids, merged_df['total']), merged_df['accuracy'], (xi, yi), method='linear')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot surface\n",
    "surf = ax.plot_surface(xi, yi, zi, cmap=mpl.colormaps['hot_r'])\n",
    "\n",
    "# Labeling the projects\n",
    "ax.set_xticks(range(len(unique_projects)))\n",
    "ax.set_xticklabels(unique_projects, rotation=45, ha='right', fontsize=12) \n",
    "\n",
    "# Setting labels\n",
    "ax.set_ylabel(\"Total power consumption (Wh)\", fontsize=12)\n",
    "ax.set_zlabel('Accuracy (%)', fontsize=12)\n",
    "\n",
    "# Adding a color bar\n",
    "cbar = fig.colorbar(surf)\n",
    "cbar.ax.tick_params(labelsize=16)  # Set colorbar label size\n",
    "\n",
    "plt.tight_layout()  # This will ensure that the labels don't overlap\n",
    "plt.savefig(FIGURES_PATH + '/model_vs_total_power_vs_accuracy_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_stats_train\n",
    "merged_df = merged_df.sort_values(['project_name', 'epoch'])\n",
    "merged_df['line_power'] = (merged_df['cpu_delta_power_w'] + (merged_df['gpu_power_w']/1000) + merged_df['ram_power_w']) * (merged_df['duration(s)']/1000)\n",
    "merged_df['total'] = merged_df.groupby('project_name')['line_power'].cumsum() / 3600\n",
    "\n",
    "# Convert 'project_name' to ordinal\n",
    "unique_projects = merged_df['project_name'].unique()\n",
    "project_dict = {project: i for i, project in enumerate(unique_projects)}\n",
    "project_ids = merged_df['project_name'].map(project_dict)\n",
    "\n",
    "# Define grid\n",
    "xi = np.linspace(project_ids.min(), project_ids.max(), 100)\n",
    "yi = np.linspace(merged_df['accuracy'].min(), merged_df['accuracy'].max(), 100)\n",
    "xi, yi = np.meshgrid(xi, yi)\n",
    "\n",
    "# Interpolate\n",
    "zi = griddata((project_ids, merged_df['accuracy']), merged_df['total'], (xi, yi), method='linear')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot surface\n",
    "surf = ax.plot_surface(xi, yi, zi, cmap='viridis')\n",
    "\n",
    "# Diagonal x-ticks\n",
    "ax.set_xticks(range(len(unique_projects)))\n",
    "ax.set_xticklabels(unique_projects, rotation=45, ha='right')  # 45-degree angle\n",
    "\n",
    "# Removing x-label\n",
    "ax.set_xlabel('')\n",
    "\n",
    "# Setting labels\n",
    "ax.set_zlabel(\"Total power consumption (Wh)\")\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "\n",
    "# Adding a color bar\n",
    "fig.colorbar(surf)\n",
    "\n",
    "plt.tight_layout()  # This will ensure that the labels don't overlap\n",
    "plt.savefig(FIGURES_PATH + '/model_vs_accuracy_vs_total_power_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_energy_consumption_carbontracker():\n",
    "    files = os.listdir(SERVER_PATH)\n",
    "    data = []\n",
    "    \n",
    "    for file in files:\n",
    "        if file.endswith('carbontracker_output.log'):\n",
    "            file_path = os.path.join(SERVER_PATH, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for i in range(len(lines)):\n",
    "                    if 'Actual consumption for' in lines[i]:\n",
    "                        if i + 4 < len(lines):\n",
    "                            energy_line = lines[i+2].strip()\n",
    "                            energy_value = float(energy_line.split('\\t')[1].split(' ')[0])\n",
    "                            data.append((file.split('_')[0], energy_value))\n",
    "                        break\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['project_name', 'CarbonTracker'])\n",
    "    return df\n",
    "\n",
    "\n",
    "df_stats_train_tmp = df_stats_train.groupby('project_name').mean().reset_index()\n",
    "df_stats_train_tmp['FROST'] = (df_stats_train_tmp['cpu_delta_power_w'] + (df_stats_train_tmp['gpu_power_w']/1000) + df_stats_train_tmp['ram_power_w']) * (df_stats_train_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "df_stats_train_tmp = df_stats_train_tmp[[ 'project_name', 'FROST']]\n",
    "\n",
    "df_stats_eco2ai_tmp = df_eco2ai_results_train.groupby('experiment_description').sum().reset_index()\n",
    "df_stats_eco2ai_tmp['Eco2AI'] = df_stats_eco2ai_tmp['power_consumption(kWh)'] * 1000\n",
    "df_stats_eco2ai_tmp = df_stats_eco2ai_tmp[['experiment_description', 'Eco2AI']]\n",
    "df_stats_eco2ai_tmp.rename(columns={'experiment_description': 'project_name'}, inplace=True)\n",
    "\n",
    "df_codecarbon_tmp = df_codecarbon_results_train.groupby('project_name')[['cpu_power', 'gpu_power', 'ram_power']].mean().reset_index()\n",
    "df_codecarbon_tmp2 = df_codecarbon_results_train.groupby('project_name')['duration'].first().reset_index()\n",
    "df_codecarbon_tmp = df_codecarbon_tmp.merge(df_codecarbon_tmp2, on='project_name', how='left')\n",
    "\n",
    "df_carbontracker_tmp = extract_energy_consumption_carbontracker()\n",
    "df_carbontracker_tmp['CarbonTracker'] = df_carbontracker_tmp['CarbonTracker'] * 1000\n",
    "\n",
    "merged_duration_df = pd.DataFrame()\n",
    "merged_duration_df['CodeCarbon'] = df_codecarbon_results_train.groupby('project_name')['energy_consumed'].max()*1000\n",
    "merged_duration_df.reset_index(inplace=True)\n",
    "merged_duration_df['CodeCarbon_correct'] = (df_codecarbon_tmp['cpu_power'] + df_codecarbon_tmp['gpu_power'] + df_codecarbon_tmp['ram_power']) * df_codecarbon_tmp['duration']*EPOCHS / 3600\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_carbontracker_tmp, on=['project_name'])\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_stats_eco2ai_tmp, on=['project_name'])\n",
    "merged_duration_df = pd.merge(merged_duration_df, df_stats_train_tmp, on=['project_name'])\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=2.5)\n",
    "\n",
    "sns.catplot(x=\"project_name\", y=\"value\", hue=\"variable\", kind=\"bar\", errorbar=lambda x: (x.min(), x.max()), data=pd.melt(merged_duration_df, id_vars=['project_name']), height=16, aspect=2/1, legend_out=False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Watts per hour (Wh) from the different tools')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Watts per hour (Wh)\")\n",
    "plt.legend(loc='upper right', title='Experiment')\n",
    "\n",
    "plt.savefig(FIGURES_PATH + '/watts_per_hour_all_tools_' + SERVER_NAME + '.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sustainable-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88730e4ff6727908bf7e963a7adc99f19dad5642eb3fcb8a30bc59444df1fc99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
