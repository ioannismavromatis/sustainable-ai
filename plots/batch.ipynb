{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..', 'utils'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import format_time as ft\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import griddata\n",
    "from adjustText import adjust_text\n",
    "\n",
    "\n",
    "EPOCHS = 200\n",
    "SAMPLES = 50000\n",
    "\n",
    "FIGURES_PATH = '../figures/'\n",
    "isExist = os.path.exists(FIGURES_PATH)\n",
    "if not isExist:\n",
    "    os.makedirs(FIGURES_PATH)\n",
    "\n",
    "RESULTS_PATH = '../results_all/'\n",
    "BATCH_PATH = RESULTS_PATH + 'batch_experiments/'\n",
    "df_stats_train = {}\n",
    "df_stats_test = {}\n",
    "stats_train_all = {}\n",
    "stats_test_all = {}\n",
    "model_size_all = {}\n",
    "\n",
    "\n",
    "def process_data(models, stats, df_stats):\n",
    "    for model in models:\n",
    "        tmp_dict = stats[model]\n",
    "        if model in model_size.keys():\n",
    "            model_size_tmp = model_size[model]\n",
    "            for epoch in tmp_dict.keys():\n",
    "                filtered = filter(lambda num: num >= 0, tmp_dict[epoch]['cpu_delta_power_w'])\n",
    "                tmp_dict[epoch]['cpu_delta_power_w'] = list(filtered)\n",
    "\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'start_time'] = tmp_dict[epoch]['start_time']\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'stop_time'] = tmp_dict[epoch]['stop_time']\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'cpu_energy_uj'] = np.mean(tmp_dict[epoch]['cpu_energy_uj'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'cpu_delta_power_w'] = np.mean(tmp_dict[epoch]['cpu_delta_power_w'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'cpu_percent'] = np.mean(tmp_dict[epoch]['cpu_percent'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'cpu_memory_percent'] = np.mean(tmp_dict[epoch]['cpu_memory_percent'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'cpu_temperature_c'] = np.mean(tmp_dict[epoch]['cpu_temperature_c'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'gpu_power_w'] = np.mean(tmp_dict[epoch]['gpu_power_w'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'gpu_temperature_c'] = np.mean(tmp_dict[epoch]['gpu_temperature_c'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'gpu_memory_free_b'] = np.mean(tmp_dict[epoch]['gpu_memory_free_b'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'gpu_memory_used_b'] = np.mean(tmp_dict[epoch]['gpu_memory_used_b'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'gpu_percent'] = np.mean(tmp_dict[epoch]['gpu_percent'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'ram_power_w'] = np.mean(tmp_dict[epoch]['ram_power_w'])\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'size_mb'] = model_size_tmp['size_mb']\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'parameters'] = model_size_tmp['parameters']\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'buffer'] = model_size_tmp['buffer']\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'macs'] = model_size_tmp['macs']\n",
    "                df_stats.loc[(df_stats['project_name'] == model) & (df_stats['epoch'] == int(epoch)), 'trainable_params'] = model_size_tmp['trainable_params']\n",
    "    \n",
    "    return df_stats\n",
    "\n",
    "\n",
    "# Create a list to store the numbers\n",
    "batch_sizes = []\n",
    "for folder in os.listdir(BATCH_PATH):\n",
    "    if folder.startswith(\"results_\"):\n",
    "        number = int(folder[8:])\n",
    "        batch_sizes.append(number)\n",
    "\n",
    "        df_stats_train_tmp = pd.read_csv(BATCH_PATH + folder + r'/mlresults_stats_train.csv')\n",
    "        df_stats_train_tmp['duration(s)'] = df_stats_train_tmp['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "        df_stats_train_tmp['step(ms)'] = df_stats_train_tmp['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "        \n",
    "        models = df_stats_train_tmp.project_name.unique()\n",
    "        \n",
    "        df_stats_test_tmp = pd.read_csv(BATCH_PATH + folder + r'/mlresults_stats_test.csv')\n",
    "        df_stats_test_tmp['duration(s)'] = df_stats_test_tmp['duration(s)'].apply(lambda x: ft.plot_time(x))\n",
    "        df_stats_test_tmp['step(ms)'] = df_stats_test_tmp['step(ms)'].apply(lambda x: ft.plot_time(x))\n",
    "        \n",
    "        df_stats_test[str(number)] = df_stats_test_tmp\n",
    "        \n",
    "        with open(BATCH_PATH + folder + '/stats_train.json') as f:\n",
    "            stats_train = json.load(f)\n",
    "        stats_train = stats_train['exp_0']\n",
    "        stats_train_all[str(number)] = stats_train\n",
    "\n",
    "        with open(BATCH_PATH + folder + '/stats_test.json') as f:\n",
    "            stats_test = json.load(f)\n",
    "        stats_test = stats_test['exp_0']\n",
    "        stats_test_all[str(number)] = stats_test\n",
    "\n",
    "        with open(BATCH_PATH + folder + '/model_size.json') as f:\n",
    "            model_size = json.load(f)\n",
    "        model_size_all[str(number)] = model_size\n",
    "        \n",
    "        models = df_stats_train_tmp.project_name.unique()\n",
    "        \n",
    "        df_stats_train_tmp = process_data(models, stats_train, df_stats_train_tmp)\n",
    "        df_stats_train_tmp = df_stats_train_tmp.groupby('project_name').mean().reset_index()\n",
    "        df_stats_train_tmp['total'] = (df_stats_train_tmp['cpu_delta_power_w'] + (df_stats_train_tmp['gpu_power_w']/1000) + df_stats_train_tmp['ram_power_w']) * (df_stats_train_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "        df_stats_train[str(number)] = df_stats_train_tmp\n",
    "        \n",
    "        df_stats_test_tmp = process_data(models, stats_test, df_stats_test_tmp)\n",
    "        df_stats_test_tmp = df_stats_test_tmp.groupby('project_name').mean().reset_index()\n",
    "        df_stats_test_tmp['total'] = (df_stats_test_tmp['cpu_delta_power_w'] + (df_stats_test_tmp['gpu_power_w']/1000) + df_stats_test_tmp['ram_power_w']) * (df_stats_test_tmp['duration(s)']/1000*EPOCHS / 3600)\n",
    "        df_stats_test[str(number)] = df_stats_test_tmp\n",
    "\n",
    "\n",
    "batch_sizes = sorted(batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "for batch_size in batch_sizes:\n",
    "    temp_df = df_stats_train[str(batch_size)][['project_name', 'total']].copy()\n",
    "    temp_df['batch_size'] = batch_size\n",
    "    final_df = pd.concat([final_df, temp_df], ignore_index=True)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"batch_size\", y=\"total\", data=final_df, hue=\"project_name\")\n",
    "plt.title('Total power consumption as a function of the batch size (training)')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Total power consumption (Wh)\")\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.2, 0.9))\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/training_batch_total_power.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "for batch_size in batch_sizes:\n",
    "    temp_df = df_stats_test[str(batch_size)][['project_name', 'total']].copy()\n",
    "    temp_df['batch_size'] = batch_size\n",
    "    final_df = pd.concat([final_df, temp_df], ignore_index=True)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,5.27)}, style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"batch_size\", y=\"total\", data=final_df, hue=\"project_name\")\n",
    "plt.title('Total power consumption as a function of the batch size (testing)')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Total power consumption (Wh)\")\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.2, 0.9))\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/testing_batch_total_power.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['VGG', 'DPN', 'RegNet', 'SimpleDLA', 'DenseNet']\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "for batch_size in batch_sizes:\n",
    "    temp_df = df_stats_train[str(batch_size)][['project_name', 'total']].copy()\n",
    "    temp_df = temp_df[temp_df['project_name'].isin(models)]\n",
    "    temp_df['batch_size'] = batch_size\n",
    "    final_df = pd.concat([final_df, temp_df], ignore_index=True)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,4.27)}, style=\"whitegrid\",font_scale=1.3)\n",
    "ax = sns.barplot(x=\"batch_size\", y=\"total\", data=final_df, hue=\"project_name\")\n",
    "plt.title('Total power consumption as a function of the batch size (training)')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Total power consumption (Wh)\")\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.23, 0.75))\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/training_batch_total_power.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "for batch_size in batch_sizes:\n",
    "    temp_df = df_stats_test[str(batch_size)][['project_name', 'total']].copy()\n",
    "    temp_df = temp_df[temp_df['project_name'].isin(models)]\n",
    "    temp_df['batch_size'] = batch_size\n",
    "    final_df = pd.concat([final_df, temp_df], ignore_index=True)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,4.27)}, style=\"whitegrid\", font_scale=1.3)\n",
    "ax = sns.barplot(x=\"batch_size\", y=\"total\", data=final_df, hue=\"project_name\")\n",
    "plt.title('Total power consumption as a function of the batch size (testing)')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Total power consumption (Wh)\")\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.23, 0.75))\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/testing_batch_total_power.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['VGG', 'DPN', 'RegNet', 'SimpleDLA', 'DenseNet']\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "for batch_size in batch_sizes:\n",
    "    temp_df = df_stats_train[str(batch_size)][['project_name', 'gpu_percent']].copy()\n",
    "    temp_df = temp_df[temp_df['project_name'].isin(models)]\n",
    "    temp_df['batch_size'] = batch_size\n",
    "    final_df = pd.concat([final_df, temp_df], ignore_index=True)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,4.27)}, style=\"whitegrid\",font_scale=1.3)\n",
    "ax = sns.barplot(x=\"batch_size\", y=\"gpu_percent\", data=final_df, hue=\"project_name\")\n",
    "plt.title('GPU Utilisation as a function of the batch size (training)')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"GPU Utilisation (%)\")\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.23, 0.75))\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/training_batch_total_power.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "for batch_size in batch_sizes:\n",
    "    temp_df = df_stats_test[str(batch_size)][['project_name', 'gpu_percent']].copy()\n",
    "    temp_df = temp_df[temp_df['project_name'].isin(models)]\n",
    "    temp_df['batch_size'] = batch_size\n",
    "    final_df = pd.concat([final_df, temp_df], ignore_index=True)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,4.27)}, style=\"whitegrid\", font_scale=1.3)\n",
    "ax = sns.barplot(x=\"batch_size\", y=\"gpu_percent\", data=final_df, hue=\"project_name\")\n",
    "plt.title('GPU Utilisation as a function of the batch size (testing)')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"GPU Utilisation (%)\")\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.23, 0.75))\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(FIGURES_PATH + '/testing_batch_total_power.png', bbox_inches='tight', format='png', dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sustainable-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
